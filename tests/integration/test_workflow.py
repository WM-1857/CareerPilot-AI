#!/usr/bin/env python3
"""
LangGraphå®Œæ•´å·¥ä½œæµé›†æˆæµ‹è¯•
æµ‹è¯•ç«¯åˆ°ç«¯çš„å·¥ä½œæµæ‰§è¡Œå’Œç”¨æˆ·äº¤äº’
"""

import os
import sys
import json
import time
from typing import Dict, Any, Optional
from unittest.mock import patch, MagicMock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

# åŠ è½½ç¯å¢ƒå˜é‡
def load_env():
    env_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
    if os.path.exists(env_file):
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

load_env()

try:
    from src.services.career_graph import CareerNavigatorGraph
    from src.models.career_state import (
        CareerNavigatorState, WorkflowStage, UserProfile, UserSatisfactionLevel,
        create_initial_state, StateUpdater
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·å…ˆè¿è¡Œç¯å¢ƒæµ‹è¯•ç¡®ä¿æ‰€æœ‰ä¾èµ–æ­£å¸¸")
    sys.exit(1)


class WorkflowIntegrationTester:
    """å·¥ä½œæµé›†æˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results = {}
        self.graph = CareerNavigatorGraph()
        self.test_user_profile = {
            "user_id": "test_user_001",
            "age": 28,
            "education_level": "æœ¬ç§‘",
            "work_experience": 3,
            "current_position": "è½¯ä»¶å·¥ç¨‹å¸ˆ",
            "industry": "äº’è”ç½‘",
            "skills": ["Python", "JavaScript", "React"],
            "interests": ["äººå·¥æ™ºèƒ½", "äº§å“ç®¡ç†"],
            "career_goals": "å¸Œæœ›è½¬å‘AIäº§å“ç»ç†æ–¹å‘å‘å±•",
            "location": "åŒ—äº¬",
            "salary_expectation": "30-50ä¸‡"
        }
        
        # æ¨¡æ‹ŸLLMå“åº”
        self.mock_responses = {
            "goal_clarity": {
                "success": True,
                "content": json.dumps({
                    "is_goal_clear": False,
                    "clarity_score": 45,
                    "analysis_details": "ç›®æ ‡éœ€è¦è¿›ä¸€æ­¥æ˜ç¡®"
                })
            },
            "strategy": {
                "success": True,
                "content": json.dumps({
                    "strategy_overview": "åˆ¶å®šä¸ªæ€§åŒ–èŒä¸šåˆ†æç­–ç•¥"
                })
            },
            "user_analysis": {
                "success": True,
                "content": json.dumps({
                    "strengths": ["æŠ€æœ¯èƒŒæ™¯å¼º", "å­¦ä¹ èƒ½åŠ›å¼º"],
                    "improvement_areas": ["äº§å“æ€ç»´", "å¸‚åœºæ´å¯Ÿ"],
                    "recommendations": ["åŠ å¼ºäº§å“çŸ¥è¯†", "å…³æ³¨AIè¡Œä¸šåŠ¨æ€"]
                })
            },
            "industry_research": {
                "success": True,
                "content": json.dumps({
                    "trends": ["AIæŠ€æœ¯å¿«é€Ÿå‘å±•", "äº§å“ç»ç†éœ€æ±‚å¢é•¿"],
                    "opportunities": ["AIäº§å“ç»ç†", "æŠ€æœ¯äº§å“ä¸“å®¶"],
                    "challenges": ["ç«äº‰æ¿€çƒˆ", "æŠ€èƒ½è¦æ±‚é«˜"]
                })
            },
            "career_analysis": {
                "success": True,
                "content": json.dumps({
                    "career_paths": ["AIäº§å“ç»ç†", "æŠ€æœ¯äº§å“ç»ç†"],
                    "skill_gaps": ["äº§å“è®¾è®¡", "ç”¨æˆ·ç ”ç©¶"],
                    "salary_range": "25-45ä¸‡"
                })
            },
            "integrated_report": {
                "success": True,
                "content": json.dumps({
                    "executive_summary": "åŸºäºæ‚¨çš„æŠ€æœ¯èƒŒæ™¯ï¼Œå»ºè®®è½¬å‘AIäº§å“ç»ç†",
                    "career_match": {
                        "recommended_career": "AIäº§å“ç»ç†",
                        "match_score": 0.75
                    },
                    "recommendations": ["å­¦ä¹ äº§å“è®¾è®¡", "äº†è§£AIåº”ç”¨åœºæ™¯"]
                })
            },
            "goal_decomposition": {
                "success": True,
                "content": json.dumps({
                    "short_term_goals": ["å­¦ä¹ äº§å“åŸºç¡€çŸ¥è¯†", "å‚ä¸äº§å“é¡¹ç›®"],
                    "medium_term_goals": ["è·å¾—äº§å“ç»ç†èŒä½", "ç§¯ç´¯äº§å“ç»éªŒ"],
                    "long_term_goals": ["æˆä¸ºèµ„æ·±AIäº§å“ç»ç†", "å¸¦é¢†äº§å“å›¢é˜Ÿ"]
                })
            },
            "schedule": {
                "success": True,
                "content": json.dumps({
                    "schedule_overview": "6ä¸ªæœˆè½¬å‹è®¡åˆ’",
                    "timeline": "çŸ­æœŸ3ä¸ªæœˆï¼Œä¸­æœŸ6ä¸ªæœˆï¼Œé•¿æœŸ2å¹´",
                    "milestones": ["å®Œæˆäº§å“è¯¾ç¨‹", "è·å¾—å®ä¹ æœºä¼š", "æ­£å¼è½¬å²—"]
                })
            }
        }
    
    def print_separator(self, title: str):
        """æ‰“å°åˆ†éš”ç¬¦"""
        print(f"\n{'='*60}")
        print(f"  {title}")
        print('='*60)
    
    def print_result(self, test_name: str, success: bool, message: str, details: str = ""):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{status} {test_name}: {message}")
        if details:
            print(f"   ğŸ“ {details}")
        self.results[test_name] = {"success": success, "message": message, "details": details}
        return success
    
    def setup_llm_mocks(self):
        """è®¾ç½®LLMæ¨¡æ‹Ÿ"""
        self.mock_llm_service = MagicMock()
        
        # é…ç½®å„ç§LLMæ–¹æ³•çš„è¿”å›å€¼
        self.mock_llm_service.analyze_career_goal_clarity.return_value = self.mock_responses["goal_clarity"]
        self.mock_llm_service.create_analysis_strategy.return_value = self.mock_responses["strategy"]
        self.mock_llm_service.analyze_user_profile.return_value = self.mock_responses["user_analysis"]
        self.mock_llm_service.research_industry_trends.return_value = self.mock_responses["industry_research"]
        self.mock_llm_service.analyze_career_opportunities.return_value = self.mock_responses["career_analysis"]
        self.mock_llm_service.generate_integrated_report.return_value = self.mock_responses["integrated_report"]
        self.mock_llm_service.decompose_career_goals.return_value = self.mock_responses["goal_decomposition"]
        self.mock_llm_service.create_action_schedule.return_value = self.mock_responses["schedule"]
        
        return patch('src.services.llm_service.llm_service', self.mock_llm_service)
    
    def test_complete_workflow_happy_path(self) -> bool:
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµçš„é¡ºåˆ©è·¯å¾„"""
        print("\nğŸ¯ æµ‹è¯•å®Œæ•´å·¥ä½œæµé¡ºåˆ©è·¯å¾„...")
        
        try:
            with self.setup_llm_mocks():
                # 1. åˆ›å»ºä¼šè¯
                user_message = "æˆ‘æƒ³ä»è½¯ä»¶å·¥ç¨‹å¸ˆè½¬å‘AIäº§å“ç»ç†"
                initial_state = self.graph.create_session(self.test_user_profile, user_message)
                
                if not initial_state.get("session_id"):
                    return self.print_result(
                        "å®Œæ•´å·¥ä½œæµ_ä¼šè¯åˆ›å»º",
                        False,
                        "ä¼šè¯åˆ›å»ºå¤±è´¥",
                        "æ— æ³•è·å–session_id"
                    )
                
                # 2. è¿è¡Œå·¥ä½œæµåˆ°ç”¨æˆ·åé¦ˆé˜¶æ®µ
                current_state = initial_state
                step_count = 0
                max_steps = 20
                
                while step_count < max_steps:
                    step_count += 1
                    
                    # è¿è¡Œä¸€æ­¥å·¥ä½œæµ
                    try:
                        result = None
                        for state_update in self.graph.app.stream(current_state):
                            # è·å–æœ€æ–°çŠ¶æ€
                            last_node = list(state_update.keys())[-1]
                            result = state_update[last_node]
                            
                            # å¦‚æœåˆ°è¾¾ç”¨æˆ·åé¦ˆé˜¶æ®µï¼Œåœæ­¢
                            if result.get("current_stage") == WorkflowStage.USER_FEEDBACK:
                                break
                        
                        if result:
                            current_state = result
                        else:
                            break
                        
                        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç”¨æˆ·åé¦ˆé˜¶æ®µ
                        if current_state.get("current_stage") == WorkflowStage.USER_FEEDBACK:
                            break
                            
                    except Exception as e:
                        return self.print_result(
                            "å®Œæ•´å·¥ä½œæµ_æ‰§è¡Œ",
                            False,
                            f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸(æ­¥éª¤{step_count})",
                            f"å¼‚å¸¸: {str(e)}"
                        )
                
                # 3. éªŒè¯åˆ°è¾¾ç”¨æˆ·åé¦ˆé˜¶æ®µ
                if current_state.get("current_stage") != WorkflowStage.USER_FEEDBACK:
                    return self.print_result(
                        "å®Œæ•´å·¥ä½œæµ_è¿›åº¦",
                        False,
                        f"æœªåˆ°è¾¾ç”¨æˆ·åé¦ˆé˜¶æ®µ",
                        f"å½“å‰é˜¶æ®µ: {current_state.get('current_stage')}"
                    )
                
                # 4. éªŒè¯å¿…è¦çš„åˆ†æç»“æœ
                required_results = [
                    "self_insight_result",
                    "industry_research_result", 
                    "career_analysis_result",
                    "integrated_report"
                ]
                
                missing_results = [r for r in required_results if not current_state.get(r)]
                
                if missing_results:
                    return self.print_result(
                        "å®Œæ•´å·¥ä½œæµ_ç»“æœ",
                        False,
                        "åˆ†æç»“æœä¸å®Œæ•´",
                        f"ç¼ºå°‘: {missing_results}"
                    )
                
                # 5. æ¨¡æ‹Ÿç”¨æˆ·æ»¡æ„åé¦ˆå¹¶ç»§ç»­
                satisfied_state = self.graph.update_user_feedback(
                    current_state,
                    UserSatisfactionLevel.SATISFIED,
                    "åˆ†æå¾ˆå¥½ï¼Œæ»¡æ„"
                )
                
                # 6. ç»§ç»­æ‰§è¡Œåˆ°å®Œæˆ
                final_step_count = 0
                while final_step_count < 10:
                    final_step_count += 1
                    
                    try:
                        result = None
                        for state_update in self.graph.app.stream(satisfied_state):
                            last_node = list(state_update.keys())[-1]
                            result = state_update[last_node]
                            
                            # å¦‚æœå®Œæˆæˆ–éœ€è¦æœ€ç»ˆç¡®è®¤ï¼Œåœæ­¢
                            if (result.get("current_stage") in [WorkflowStage.COMPLETED, WorkflowStage.FINAL_CONFIRMATION]):
                                break
                        
                        if result:
                            satisfied_state = result
                        else:
                            break
                            
                        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                        if satisfied_state.get("current_stage") in [WorkflowStage.COMPLETED, WorkflowStage.FINAL_CONFIRMATION]:
                            break
                            
                    except Exception as e:
                        return self.print_result(
                            "å®Œæ•´å·¥ä½œæµ_æœ€ç»ˆæ‰§è¡Œ",
                            False,
                            f"æœ€ç»ˆæ‰§è¡Œå¼‚å¸¸(æ­¥éª¤{final_step_count})",
                            f"å¼‚å¸¸: {str(e)}"
                        )
                
                # 7. éªŒè¯æœ€ç»ˆçŠ¶æ€
                final_stage = satisfied_state.get("current_stage")
                expected_stages = [WorkflowStage.FINAL_CONFIRMATION, WorkflowStage.SCHEDULE_PLANNING]
                
                if final_stage in expected_stages:
                    return self.print_result(
                        "å®Œæ•´å·¥ä½œæµ_é¡ºåˆ©è·¯å¾„",
                        True,
                        "å®Œæ•´å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
                        f"åˆ°è¾¾é˜¶æ®µ: {final_stage}, æ€»æ­¥éª¤: {step_count + final_step_count}"
                    )
                else:
                    return self.print_result(
                        "å®Œæ•´å·¥ä½œæµ_é¡ºåˆ©è·¯å¾„",
                        False,
                        "æœªåˆ°è¾¾é¢„æœŸæœ€ç»ˆé˜¶æ®µ",
                        f"æœ€ç»ˆé˜¶æ®µ: {final_stage}"
                    )
                    
        except Exception as e:
            return self.print_result(
                "å®Œæ•´å·¥ä½œæµ_é¡ºåˆ©è·¯å¾„",
                False,
                "å®Œæ•´å·¥ä½œæµæµ‹è¯•å¼‚å¸¸",
                f"å¼‚å¸¸: {str(e)}"
            )
    
    def test_iteration_workflow(self) -> bool:
        """æµ‹è¯•è¿­ä»£å·¥ä½œæµ"""
        print("\nğŸ”„ æµ‹è¯•è¿­ä»£å·¥ä½œæµ...")
        
        try:
            with self.setup_llm_mocks():
                # 1. è¿è¡Œåˆ°ç”¨æˆ·åé¦ˆé˜¶æ®µ
                user_message = "æˆ‘æƒ³è½¬å‘AIäº§å“ç»ç†"
                initial_state = self.graph.create_session(self.test_user_profile, user_message)
                
                # å¿«é€Ÿè¿è¡Œåˆ°ç”¨æˆ·åé¦ˆé˜¶æ®µ
                current_state = initial_state
                step_count = 0
                
                while step_count < 15:
                    step_count += 1
                    
                    try:
                        result = None
                        for state_update in self.graph.app.stream(current_state):
                            last_node = list(state_update.keys())[-1]
                            result = state_update[last_node]
                            
                            if result.get("current_stage") == WorkflowStage.USER_FEEDBACK:
                                break
                        
                        if result:
                            current_state = result
                            
                        if current_state.get("current_stage") == WorkflowStage.USER_FEEDBACK:
                            break
                            
                    except Exception:
                        continue
                
                if current_state.get("current_stage") != WorkflowStage.USER_FEEDBACK:
                    return self.print_result(
                        "è¿­ä»£å·¥ä½œæµ_å‡†å¤‡",
                        False,
                        "æ— æ³•åˆ°è¾¾ç”¨æˆ·åé¦ˆé˜¶æ®µ",
                        f"å½“å‰é˜¶æ®µ: {current_state.get('current_stage')}"
                    )
                
                # 2. æ¨¡æ‹Ÿç”¨æˆ·ä¸æ»¡æ„åé¦ˆ
                original_iteration_count = current_state.get("iteration_count", 0)
                
                dissatisfied_state = self.graph.update_user_feedback(
                    current_state,
                    UserSatisfactionLevel.DISSATISFIED,
                    "æˆ‘å¸Œæœ›é‡ç‚¹å…³æ³¨å¤§æ¨¡å‹ç›¸å…³çš„AIäº§å“ç»ç†å²—ä½"
                )
                
                # éªŒè¯è¿­ä»£è®¡æ•°å¢åŠ 
                new_iteration_count = dissatisfied_state.get("iteration_count", 0)
                if new_iteration_count <= original_iteration_count:
                    return self.print_result(
                        "è¿­ä»£å·¥ä½œæµ_è®¡æ•°",
                        False,
                        "è¿­ä»£è®¡æ•°æœªå¢åŠ ",
                        f"åŸå§‹: {original_iteration_count}, æ–°çš„: {new_iteration_count}"
                    )
                
                # 3. éªŒè¯åé¦ˆå†å²è®°å½•
                feedback_history = dissatisfied_state.get("user_feedback_history", [])
                if not feedback_history or len(feedback_history) == 0:
                    return self.print_result(
                        "è¿­ä»£å·¥ä½œæµ_åé¦ˆè®°å½•",
                        False,
                        "åé¦ˆå†å²æœªè®°å½•",
                        f"åé¦ˆå†å²é•¿åº¦: {len(feedback_history)}"
                    )
                
                # 4. è¿è¡Œè¿­ä»£å·¥ä½œæµ
                iteration_result = None
                iteration_steps = 0
                
                while iteration_steps < 10:
                    iteration_steps += 1
                    
                    try:
                        result = None
                        for state_update in self.graph.app.stream(dissatisfied_state):
                            last_node = list(state_update.keys())[-1]
                            result = state_update[last_node]
                            
                            # å¦‚æœåˆå›åˆ°ç”¨æˆ·åé¦ˆé˜¶æ®µï¼Œè¯´æ˜è¿­ä»£å®Œæˆ
                            if result.get("current_stage") == WorkflowStage.USER_FEEDBACK:
                                iteration_result = result
                                break
                        
                        if iteration_result:
                            break
                            
                        if result:
                            dissatisfied_state = result
                            
                    except Exception:
                        continue
                
                # 5. éªŒè¯è¿­ä»£ç»“æœ
                if iteration_result:
                    # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ–°çš„åˆ†æç»“æœ
                    has_updated_results = (
                        iteration_result.get("self_insight_result") and
                        iteration_result.get("industry_research_result") and
                        iteration_result.get("career_analysis_result") and
                        iteration_result.get("integrated_report")
                    )
                    
                    if has_updated_results:
                        return self.print_result(
                            "è¿­ä»£å·¥ä½œæµ",
                            True,
                            "è¿­ä»£å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
                            f"è¿­ä»£æ¬¡æ•°: {iteration_result.get('iteration_count')}, æ­¥éª¤: {iteration_steps}"
                        )
                    else:
                        return self.print_result(
                            "è¿­ä»£å·¥ä½œæµ",
                            False,
                            "è¿­ä»£ç»“æœä¸å®Œæ•´",
                            "ç¼ºå°‘æ›´æ–°çš„åˆ†æç»“æœ"
                        )
                else:
                    return self.print_result(
                        "è¿­ä»£å·¥ä½œæµ",
                        False,
                        "è¿­ä»£å·¥ä½œæµæœªå®Œæˆ",
                        f"æ‰§è¡Œäº†{iteration_steps}æ­¥ä½†æœªè¿”å›ç»“æœ"
                    )
                    
        except Exception as e:
            return self.print_result(
                "è¿­ä»£å·¥ä½œæµ",
                False,
                "è¿­ä»£å·¥ä½œæµæµ‹è¯•å¼‚å¸¸",
                f"å¼‚å¸¸: {str(e)}"
            )
    
    def test_state_consistency(self) -> bool:
        """æµ‹è¯•çŠ¶æ€ä¸€è‡´æ€§"""
        print("\nğŸ” æµ‹è¯•çŠ¶æ€ä¸€è‡´æ€§...")
        
        try:
            with self.setup_llm_mocks():
                # 1. åˆ›å»ºåˆå§‹çŠ¶æ€
                user_message = "æµ‹è¯•çŠ¶æ€ä¸€è‡´æ€§"
                initial_state = self.graph.create_session(self.test_user_profile, user_message)
                
                # 2. è¿è¡Œå‡ æ­¥å·¥ä½œæµ
                current_state = initial_state
                states_history = [initial_state]
                
                for step in range(5):
                    try:
                        result = None
                        for state_update in self.graph.app.stream(current_state):
                            last_node = list(state_update.keys())[-1]
                            result = state_update[last_node]
                            break  # åªæ‰§è¡Œä¸€æ­¥
                        
                        if result:
                            current_state = result
                            states_history.append(current_state)
                        else:
                            break
                            
                    except Exception:
                        break
                
                # 3. éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
                consistency_checks = []
                
                for i, state in enumerate(states_history):
                    # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦ä¿æŒ
                    session_id = state.get("session_id")
                    user_profile = state.get("user_profile")
                    
                    if session_id == initial_state["session_id"]:
                        consistency_checks.append(f"æ­¥éª¤{i}_session_idä¸€è‡´")
                    else:
                        consistency_checks.append(f"æ­¥éª¤{i}_session_idä¸ä¸€è‡´")
                    
                    if user_profile == initial_state["user_profile"]:
                        consistency_checks.append(f"æ­¥éª¤{i}_user_profileä¸€è‡´")
                    else:
                        consistency_checks.append(f"æ­¥éª¤{i}_user_profileä¸ä¸€è‡´")
                
                # æ£€æŸ¥è¿­ä»£è®¡æ•°æ˜¯å¦å•è°ƒé€’å¢ï¼ˆå¦‚æœæœ‰åé¦ˆï¼‰
                iteration_counts = [s.get("iteration_count", 0) for s in states_history]
                is_monotonic = all(iteration_counts[i] <= iteration_counts[i+1] for i in range(len(iteration_counts)-1))
                
                if is_monotonic:
                    consistency_checks.append("è¿­ä»£è®¡æ•°å•è°ƒæ€§æ­£ç¡®")
                else:
                    consistency_checks.append("è¿­ä»£è®¡æ•°å•è°ƒæ€§é”™è¯¯")
                
                # ç»Ÿè®¡ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ
                consistent_checks = [c for c in consistency_checks if "ä¸€è‡´" in c or "æ­£ç¡®" in c]
                consistency_rate = len(consistent_checks) / len(consistency_checks)
                
                if consistency_rate >= 0.8:  # 80%ä»¥ä¸Šä¸€è‡´æ€§è®¤ä¸ºé€šè¿‡
                    return self.print_result(
                        "çŠ¶æ€ä¸€è‡´æ€§",
                        True,
                        f"çŠ¶æ€ä¸€è‡´æ€§è‰¯å¥½",
                        f"ä¸€è‡´æ€§ç‡: {consistency_rate:.2%}, æ£€æŸ¥: {len(consistency_checks)}é¡¹"
                    )
                else:
                    return self.print_result(
                        "çŠ¶æ€ä¸€è‡´æ€§",
                        False,
                        f"çŠ¶æ€ä¸€è‡´æ€§ä¸è¶³",
                        f"ä¸€è‡´æ€§ç‡: {consistency_rate:.2%}, é—®é¢˜: {[c for c in consistency_checks if 'ä¸ä¸€è‡´' in c or 'é”™è¯¯' in c]}"
                    )
                    
        except Exception as e:
            return self.print_result(
                "çŠ¶æ€ä¸€è‡´æ€§",
                False,
                "çŠ¶æ€ä¸€è‡´æ€§æµ‹è¯•å¼‚å¸¸",
                f"å¼‚å¸¸: {str(e)}"
            )
    
    def test_error_recovery(self) -> bool:
        """æµ‹è¯•é”™è¯¯æ¢å¤"""
        print("\nğŸ› ï¸ æµ‹è¯•é”™è¯¯æ¢å¤...")
        
        try:
            # 1. è®¾ç½®ä¼šå¯¼è‡´é”™è¯¯çš„LLMå“åº”
            error_mock = MagicMock()
            error_mock.analyze_career_goal_clarity.return_value = {
                "success": False,
                "error": "æ¨¡æ‹ŸAPIé”™è¯¯"
            }
            
            with patch('src.services.llm_service.llm_service', error_mock):
                # 2. å°è¯•è¿è¡Œå·¥ä½œæµ
                user_message = "æµ‹è¯•é”™è¯¯æ¢å¤"
                initial_state = self.graph.create_session(self.test_user_profile, user_message)
                
                error_occurred = False
                try:
                    result = None
                    for state_update in self.graph.app.stream(initial_state):
                        last_node = list(state_update.keys())[-1]
                        result = state_update[last_node]
                        break
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æ—¥å¿—
                    if result and result.get("error_log"):
                        error_occurred = True
                        
                except Exception:
                    error_occurred = True
                
                if error_occurred:
                    return self.print_result(
                        "é”™è¯¯æ¢å¤",
                        True,
                        "é”™è¯¯å¤„ç†æœºåˆ¶æ­£å¸¸",
                        "ç³»ç»Ÿèƒ½å¤Ÿä¼˜é›…å¤„ç†LLM APIé”™è¯¯"
                    )
                else:
                    return self.print_result(
                        "é”™è¯¯æ¢å¤",
                        False,
                        "é”™è¯¯å¤„ç†æœºåˆ¶å¼‚å¸¸",
                        "ç³»ç»Ÿæœªèƒ½æ­£ç¡®å¤„ç†APIé”™è¯¯"
                    )
                    
        except Exception as e:
            return self.print_result(
                "é”™è¯¯æ¢å¤",
                False,
                "é”™è¯¯æ¢å¤æµ‹è¯•å¼‚å¸¸",
                f"å¼‚å¸¸: {str(e)}"
            )
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
        self.print_separator("CareerNavigator å·¥ä½œæµé›†æˆæµ‹è¯•")
        
        print("ğŸ”— å¼€å§‹é›†æˆæµ‹è¯•...")
        start_time = time.time()
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        happy_path_result = self.test_complete_workflow_happy_path()
        iteration_result = self.test_iteration_workflow()
        consistency_result = self.test_state_consistency()
        error_recovery_result = self.test_error_recovery()
        
        # æ±‡æ€»ç»“æœ
        end_time = time.time()
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results.values() if r["success"])
        
        self.print_separator("æµ‹è¯•ç»“æœæ±‡æ€»")
        print(f"ğŸ“Š æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"âœ… é€šè¿‡: {passed_tests}")
        print(f"âŒ å¤±è´¥: {total_tests - passed_tests}")
        print(f"â±ï¸ è€—æ—¶: {end_time - start_time:.2f}ç§’")
        
        overall_success = all([
            happy_path_result, iteration_result, 
            consistency_result, error_recovery_result
        ])
        
        if overall_success:
            print("\nğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿé›†æˆæ­£å¸¸ã€‚")
        else:
            print("\nâš ï¸ å­˜åœ¨é›†æˆé—®é¢˜ï¼Œè¯·æ£€æŸ¥å·¥ä½œæµé€»è¾‘å’ŒçŠ¶æ€ç®¡ç†ã€‚")
        
        return {
            "overall_success": overall_success,
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "duration": end_time - start_time,
            "details": self.results
        }


def main():
    """ä¸»å‡½æ•°"""
    tester = WorkflowIntegrationTester()
    results = tester.run_all_tests()
    
    # è¿”å›é€€å‡ºç 
    exit_code = 0 if results["overall_success"] else 1
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
