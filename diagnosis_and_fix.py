"""
CareerNavigator é—®é¢˜è¯Šæ–­å’Œä¿®å¤è„šæœ¬
é’ˆå¯¹æµ‹è¯•ä¸­å‘ç°çš„é—®é¢˜è¿›è¡Œä¿®å¤
"""

import sys
import os

sys.path.insert(0, os.path.dirname(__file__))

def diagnose_llm_parsing_issue():
    """è¯Šæ–­LLMå“åº”è§£æé—®é¢˜"""
    print("ğŸ” è¯Šæ–­LLMå“åº”è§£æé—®é¢˜...")
    
    try:
        from src.services.llm_service import DashScopeService
        
        llm_service = DashScopeService()
        
        # æµ‹è¯•åè°ƒå‘˜èŠ‚ç‚¹çš„æç¤ºè¯
        coordinator_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½èŒä¸šè§„åˆ’åè°ƒå‘˜ã€‚è¯·æ ¹æ®ç”¨æˆ·ä¿¡æ¯åˆ¶å®šåˆ†æç­–ç•¥ã€‚

ç”¨æˆ·ä¿¡æ¯ï¼š
- å¹´é¾„ï¼š26å²
- å½“å‰èŒä½ï¼šäº§å“ç»ç†
- å·¥ä½œç»éªŒï¼š3å¹´
- è¡Œä¸šï¼šç”µå•†
- èŒä¸šç›®æ ‡ï¼šæˆä¸ºäº§å“æ€»ç›‘

è¯·è¿”å›JSONæ ¼å¼çš„ç­–ç•¥ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
    "strategy_overview": "ç­–ç•¥æ¦‚è¿°",
    "analysis_priorities": ["ä¼˜å…ˆçº§1", "ä¼˜å…ˆçº§2"],
    "data_sources": ["æ•°æ®æº1", "æ•°æ®æº2"],
    "timeline": "æ—¶é—´è§„åˆ’",
    "expected_outcomes": ["é¢„æœŸç»“æœ1", "é¢„æœŸç»“æœ2"]
}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
        
        print("  ğŸ“¤ æµ‹è¯•åè°ƒå‘˜æç¤ºè¯...")
        response = llm_service.call_llm(coordinator_prompt)
        
        if response.get("success"):
            content = response.get("content", "")
            print(f"  ğŸ“ LLMåŸå§‹å“åº”: {content[:200]}...")
            
            # å°è¯•è§£æJSON
            try:
                import json
                
                # æ¸…ç†å“åº”å†…å®¹
                cleaned_content = content.strip()
                if cleaned_content.startswith("```json"):
                    cleaned_content = cleaned_content[7:]
                if cleaned_content.endswith("```"):
                    cleaned_content = cleaned_content[:-3]
                if cleaned_content.startswith("```"):
                    cleaned_content = cleaned_content[3:]
                
                parsed_json = json.loads(cleaned_content)
                print("  âœ… JSONè§£ææˆåŠŸ")
                print(f"  ğŸ“‹ ç­–ç•¥æ¦‚è¿°: {parsed_json.get('strategy_overview', 'æœªçŸ¥')[:100]}...")
                return True
                
            except json.JSONDecodeError as e:
                print(f"  âŒ JSONè§£æå¤±è´¥: {e}")
                print(f"  ğŸ“ æ¸…ç†åå†…å®¹: {cleaned_content[:200]}...")
                return False
        else:
            print(f"  âŒ LLMè°ƒç”¨å¤±è´¥: {response.get('error')}")
            return False
            
    except Exception as e:
        print(f"  âŒ è¯Šæ–­å¼‚å¸¸: {e}")
        return False


def test_improved_prompt():
    """æµ‹è¯•æ”¹è¿›çš„æç¤ºè¯"""
    print("\nğŸ”§ æµ‹è¯•æ”¹è¿›çš„æç¤ºè¯...")
    
    try:
        from src.services.llm_service import DashScopeService
        
        llm_service = DashScopeService()
        
        # æ”¹è¿›çš„æç¤ºè¯
        improved_prompt = """
ä½œä¸ºèŒä¸šè§„åˆ’åè°ƒå‘˜ï¼Œè¯·ä¸ºç”¨æˆ·åˆ¶å®šåˆ†æç­–ç•¥ã€‚

ç”¨æˆ·èƒŒæ™¯ï¼šäº§å“ç»ç†ï¼Œ3å¹´ç»éªŒï¼Œç”µå•†è¡Œä¸šï¼Œç›®æ ‡æ˜¯æˆä¸ºäº§å“æ€»ç›‘ã€‚

è¯·æä¾›åˆ†æç­–ç•¥ï¼Œæ ¼å¼è¦æ±‚ï¼š
1. ç­–ç•¥æ¦‚è¿°ï¼ˆ50å­—å†…ï¼‰
2. åˆ†æé‡ç‚¹ï¼ˆåˆ—å‡º3ä¸ªè¦ç‚¹ï¼‰
3. æ•°æ®æ¥æºï¼ˆåˆ—å‡º3ä¸ªæ¥æºï¼‰
4. æ—¶é—´å®‰æ’ï¼ˆç®€è¦è¯´æ˜ï¼‰
5. é¢„æœŸæˆæœï¼ˆåˆ—å‡º3ä¸ªæˆæœï¼‰

è¯·ç›´æ¥ç»™å‡ºå†…å®¹ï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚
"""
        
        print("  ğŸ“¤ å‘é€æ”¹è¿›çš„æç¤ºè¯...")
        response = llm_service.call_llm(improved_prompt)
        
        if response.get("success"):
            content = response.get("content", "")
            print(f"  âœ… å“åº”æˆåŠŸ")
            print(f"  ğŸ“ å“åº”å†…å®¹: {content}")
            
            # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
            key_terms = ["ç­–ç•¥", "åˆ†æ", "æ•°æ®", "æ—¶é—´", "æˆæœ"]
            found_terms = [term for term in key_terms if term in content]
            
            print(f"  ğŸ“Š åŒ…å«å…³é”®è¯: {len(found_terms)}/{len(key_terms)} ({', '.join(found_terms)})")
            
            if len(found_terms) >= 3:
                print("  âœ… å“åº”è´¨é‡è‰¯å¥½")
                return True
            else:
                print("  âš ï¸ å“åº”è´¨é‡ä¸€èˆ¬")
                return False
        else:
            print(f"  âŒ LLMè°ƒç”¨å¤±è´¥: {response.get('error')}")
            return False
            
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False


def test_simple_node_execution():
    """æµ‹è¯•ç®€åŒ–çš„èŠ‚ç‚¹æ‰§è¡Œ"""
    print("\nğŸ”„ æµ‹è¯•ç®€åŒ–çš„èŠ‚ç‚¹æ‰§è¡Œ...")
    
    try:
        from src.models.career_state import UserProfile, create_initial_state
        
        # åˆ›å»ºç®€åŒ–çš„æµ‹è¯•çŠ¶æ€
        user_profile = UserProfile(
            user_id="simple_test_user",
            age=28,
            education_level="æœ¬ç§‘",
            work_experience=3,
            current_position="äº§å“ç»ç†",
            industry="ç”µå•†",
            skills=["äº§å“è®¾è®¡", "æ•°æ®åˆ†æ"],
            interests=["ç”¨æˆ·ä½“éªŒ"],
            career_goals="æˆä¸ºäº§å“æ€»ç›‘",
            location="æ·±åœ³",
            salary_expectation="25-40ä¸‡",
            additional_info={}
        )
        
        test_state = create_initial_state(user_profile, "simple_test_session")
        
        print("  ğŸ“ æµ‹è¯•çŠ¶æ€åˆ›å»ºæˆåŠŸ")
        
        # æ‰‹åŠ¨æ¨¡æ‹ŸèŠ‚ç‚¹æ‰§è¡Œé€»è¾‘ï¼ˆä¸ä¾èµ–å¤æ‚çš„LLMè§£æï¼‰
        mock_analysis_result = {
            "analysis_type": "career_strategy",
            "user_profile_summary": f"ç”¨æˆ·æ˜¯{user_profile['age']}å²çš„{user_profile['current_position']}",
            "key_insights": [
                "ç”¨æˆ·æœ‰3å¹´äº§å“ç»éªŒï¼ŒåŸºç¡€è¾ƒå¥½",
                "ç”µå•†è¡Œä¸šå‘å±•å‰æ™¯è‰¯å¥½",
                "ä»äº§å“ç»ç†åˆ°äº§å“æ€»ç›‘éœ€è¦æå‡ç®¡ç†èƒ½åŠ›"
            ],
            "recommended_actions": [
                "æ·±å…¥å­¦ä¹ å•†ä¸šåˆ†æ",
                "æå‡å›¢é˜Ÿç®¡ç†æŠ€èƒ½",
                "ç§¯ç´¯å¤§å‹é¡¹ç›®ç»éªŒ"
            ],
            "confidence_score": 0.85
        }
        
        print("  âœ… æ¨¡æ‹Ÿåˆ†æç»“æœç”ŸæˆæˆåŠŸ")
        print(f"  ğŸ“‹ åˆ†æç±»å‹: {mock_analysis_result['analysis_type']}")
        print(f"  ğŸ“Š ç½®ä¿¡åº¦: {mock_analysis_result['confidence_score']}")
        
        # æ¨¡æ‹ŸçŠ¶æ€æ›´æ–°
        updated_state = test_state.copy()
        
        # æ·»åŠ åˆ†æè¾“å‡º
        from src.models.career_state import AgentOutput
        from datetime import datetime
        
        agent_output = AgentOutput(
            output_id="test_output_001",
            agent_name="simplified_analyzer",
            task_id="test_task_001",
            output_type="èŒä¸šç­–ç•¥åˆ†æ",
            content=mock_analysis_result,
            confidence_score=0.85,
            data_sources=["ç”¨æˆ·è¾“å…¥", "æ¨¡æ‹Ÿåˆ†æ"],
            analysis_method="ç®€åŒ–åˆ†æ",
            timestamp=datetime.now(),
            quality_metrics={"completeness": 0.9, "accuracy": 0.8},
            recommendations=mock_analysis_result["recommended_actions"],
            warnings=None
        )
        
        updated_state["agent_outputs"] = [agent_output]
        
        print("  âœ… çŠ¶æ€æ›´æ–°æˆåŠŸ")
        print(f"  ğŸ“ˆ è¾“å‡ºæ•°é‡: {len(updated_state['agent_outputs'])}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ç®€åŒ–èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_concurrent_fix():
    """æµ‹è¯•å¹¶å‘é—®é¢˜ä¿®å¤"""
    print("\nğŸ”„ æµ‹è¯•å¹¶å‘é—®é¢˜ä¿®å¤...")
    
    try:
        from src.models.career_state import create_initial_state, UserProfile
        from datetime import datetime
        
        # åˆ›å»ºæµ‹è¯•çŠ¶æ€
        user_profile = UserProfile(
            user_id="concurrent_test",
            age=25,
            career_goals="æµ‹è¯•å¹¶å‘å¤„ç†",
            skills=["æµ‹è¯•"],
            interests=["å¼€å‘"],
            education_level="æœ¬ç§‘",
            work_experience=2,
            current_position="å·¥ç¨‹å¸ˆ",
            industry="æŠ€æœ¯",
            location="åŒ—äº¬",
            salary_expectation="20ä¸‡",
            additional_info={}
        )
        
        initial_state = create_initial_state(user_profile, "concurrent_session")
        
        print("  ğŸ“ åˆå§‹çŠ¶æ€åˆ›å»ºæˆåŠŸ")
        
        # æ¨¡æ‹Ÿå¤šä¸ªèŠ‚ç‚¹åŒæ—¶æ›´æ–°ï¼ˆè¿™æ˜¯å¯¼è‡´é—®é¢˜çš„åŸå› ï¼‰
        from src.models.career_state import AgentOutput
        
        # åˆ›å»ºå¤šä¸ªè¾“å‡ºï¼ˆæ¨¡æ‹Ÿå¹¶å‘èŠ‚ç‚¹ï¼‰
        outputs = []
        for i in range(3):
            output = AgentOutput(
                output_id=f"concurrent_output_{i}",
                agent_name=f"agent_{i}",
                task_id=f"task_{i}",
                output_type=f"åˆ†æç±»å‹{i}",
                content={"result": f"ç»“æœ{i}"},
                confidence_score=0.8,
                data_sources=["æµ‹è¯•"],
                analysis_method="å¹¶å‘æµ‹è¯•",
                timestamp=datetime.now(),
                quality_metrics={"test": 1.0},
                recommendations=[f"å»ºè®®{i}"],
                warnings=None
            )
            outputs.append(output)
        
        print(f"  ğŸ“Š åˆ›å»ºäº†{len(outputs)}ä¸ªå¹¶å‘è¾“å‡º")
        
        # æ­£ç¡®çš„çŠ¶æ€æ›´æ–°æ–¹å¼ï¼ˆé¿å…å¹¶å‘å†²çªï¼‰
        updated_state = initial_state.copy()
        
        # ä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰è¾“å‡ºï¼Œè€Œä¸æ˜¯åˆ†åˆ«æ·»åŠ 
        updated_state["agent_outputs"] = outputs
        
        print("  âœ… å¹¶å‘çŠ¶æ€æ›´æ–°æˆåŠŸ")
        print(f"  ğŸ“ˆ æœ€ç»ˆè¾“å‡ºæ•°é‡: {len(updated_state['agent_outputs'])}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
        return False


def create_fixed_node_example():
    """åˆ›å»ºä¿®å¤åçš„èŠ‚ç‚¹ç¤ºä¾‹"""
    print("\nğŸ”§ åˆ›å»ºä¿®å¤åçš„èŠ‚ç‚¹ç¤ºä¾‹...")
    
    fixed_node_code = '''
def fixed_coordinator_node(state):
    """ä¿®å¤åçš„åè°ƒå‘˜èŠ‚ç‚¹"""
    from src.services.llm_service import DashScopeService
    from src.models.career_state import AgentOutput
    from datetime import datetime
    
    try:
        llm_service = DashScopeService()
        user_profile = state["user_profile"]
        
        # ç®€åŒ–çš„æç¤ºè¯
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ç”¨æˆ·åˆ¶å®šèŒä¸šè§„åˆ’ç­–ç•¥ï¼š
        - å¹´é¾„ï¼š{user_profile.get('age', 'æœªçŸ¥')}
        - èŒä½ï¼š{user_profile.get('current_position', 'æœªçŸ¥')}
        - ç›®æ ‡ï¼š{user_profile.get('career_goals', 'æœªçŸ¥')}
        
        è¯·ç®€è¦è¯´æ˜ï¼š
        1. åˆ†æé‡ç‚¹
        2. å»ºè®®æ­¥éª¤
        3. é¢„æœŸç»“æœ
        
        å›ç­”è¯·ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡200å­—ã€‚
        """
        
        response = llm_service.call_llm(prompt)
        
        if response.get("success"):
            content = response.get("content", "")
            
            # ç›´æ¥ä½¿ç”¨æ–‡æœ¬å†…å®¹ï¼Œä¸å¼ºåˆ¶è§£æJSON
            analysis_result = {
                "strategy_text": content,
                "user_summary": f"{user_profile.get('age')}å²{user_profile.get('current_position')}",
                "career_goal": user_profile.get('career_goals'),
                "analysis_timestamp": datetime.now().isoformat()
            }
            
            # åˆ›å»ºè¾“å‡º
            output = AgentOutput(
                output_id=f"coord_{datetime.now().timestamp()}",
                agent_name="coordinator",
                task_id="strategy_planning",
                output_type="èŒä¸šç­–ç•¥",
                content=analysis_result,
                confidence_score=0.8,
                data_sources=["ç”¨æˆ·è¾“å…¥", "LLMåˆ†æ"],
                analysis_method="æ–‡æœ¬åˆ†æ",
                timestamp=datetime.now(),
                quality_metrics={"completeness": 0.9},
                recommendations=[content[:100] + "..."],
                warnings=None
            )
            
            # è¿”å›æ›´æ–°ï¼ˆé¿å…å¹¶å‘å†²çªï¼‰
            return {
                "agent_outputs": [output]  # è¿”å›åˆ—è¡¨ï¼Œè€Œä¸æ˜¯è¿½åŠ 
            }
        else:
            # LLMå¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆ
            fallback_result = {
                "strategy_text": "åŸºäºç”¨æˆ·èƒŒæ™¯ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨æŠ€èƒ½æå‡å’ŒèŒä¸šè§„åˆ’ã€‚",
                "user_summary": f"{user_profile.get('age')}å²{user_profile.get('current_position')}",
                "career_goal": user_profile.get('career_goals'),
                "fallback": True
            }
            
            output = AgentOutput(
                output_id=f"coord_fallback_{datetime.now().timestamp()}",
                agent_name="coordinator",
                task_id="strategy_planning",
                output_type="èŒä¸šç­–ç•¥(å¤‡ç”¨)",
                content=fallback_result,
                confidence_score=0.6,
                data_sources=["ç”¨æˆ·è¾“å…¥"],
                analysis_method="å¤‡ç”¨åˆ†æ",
                timestamp=datetime.now(),
                quality_metrics={"completeness": 0.7},
                recommendations=["å»ºè®®æ·±å…¥åˆ†æç”¨æˆ·éœ€æ±‚"],
                warnings=["ä½¿ç”¨äº†å¤‡ç”¨åˆ†ææ–¹æ¡ˆ"]
            )
            
            return {
                "agent_outputs": [output]
            }
            
    except Exception as e:
        # å¼‚å¸¸å¤„ç†
        error_output = AgentOutput(
            output_id=f"coord_error_{datetime.now().timestamp()}",
            agent_name="coordinator",
            task_id="strategy_planning",
            output_type="é”™è¯¯æŠ¥å‘Š",
            content={"error": str(e), "fallback_executed": True},
            confidence_score=0.3,
            data_sources=["é”™è¯¯å¤„ç†"],
            analysis_method="å¼‚å¸¸å¤„ç†",
            timestamp=datetime.now(),
            quality_metrics={"completeness": 0.5},
            recommendations=["è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®"],
            warnings=[f"èŠ‚ç‚¹æ‰§è¡Œå¼‚å¸¸: {str(e)}"]
        )
        
        return {
            "agent_outputs": [error_output]
        }
'''
    
    # ä¿å­˜ä¿®å¤ä»£ç ç¤ºä¾‹
    with open('fixed_node_example.py', 'w', encoding='utf-8') as f:
        f.write(fixed_node_code)
    
    print("  âœ… ä¿®å¤ä»£ç ç¤ºä¾‹å·²ä¿å­˜åˆ° fixed_node_example.py")
    print("  ğŸ“ ä¸»è¦ä¿®å¤ç‚¹ï¼š")
    print("     1. ç®€åŒ–LLMæç¤ºè¯ï¼Œé¿å…å¤æ‚JSONè§£æ")
    print("     2. æ·»åŠ å¤‡ç”¨æ–¹æ¡ˆå¤„ç†LLMå¤±è´¥")
    print("     3. æ”¹è¿›å¼‚å¸¸å¤„ç†æœºåˆ¶")
    print("     4. é¿å…å¹¶å‘çŠ¶æ€æ›´æ–°å†²çª")
    
    return True


def run_diagnosis():
    """è¿è¡Œå®Œæ•´è¯Šæ–­"""
    print("ğŸ” CareerNavigator é—®é¢˜è¯Šæ–­")
    print("=" * 50)
    
    tests = [
        ("LLMå“åº”è§£æé—®é¢˜", diagnose_llm_parsing_issue),
        ("æ”¹è¿›æç¤ºè¯æµ‹è¯•", test_improved_prompt),
        ("ç®€åŒ–èŠ‚ç‚¹æ‰§è¡Œ", test_simple_node_execution),
        ("å¹¶å‘é—®é¢˜ä¿®å¤", test_concurrent_fix),
        ("åˆ›å»ºä¿®å¤ç¤ºä¾‹", create_fixed_node_example),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
            results[test_name] = False
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š è¯Šæ–­ç»“æœæ€»ç»“")
    print("=" * 50)
    
    passed = sum(1 for result in results.values() if result)
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name:<20} {status}")
    
    print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡ ({passed/total*100:.1f}%)")
    
    print("\nğŸ’¡ ä¿®å¤å»ºè®®ï¼š")
    print("1. ç®€åŒ–LLMæç¤ºè¯ï¼Œä½¿ç”¨æ–‡æœ¬æ ¼å¼è€ŒéJSON")
    print("2. æ·»åŠ LLMè°ƒç”¨å¤±è´¥çš„å¤‡ç”¨æ–¹æ¡ˆ")
    print("3. ä¿®å¤LangGraphå¹¶å‘çŠ¶æ€æ›´æ–°é—®é¢˜")
    print("4. æ”¹è¿›é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•")
    
    return results


if __name__ == "__main__":
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['DASHSCOPE_API_KEY'] = 'sk-4b6f138ba0f74331a6092090b1c7cce1'
    os.environ['FLASK_ENV'] = 'development'
    os.environ['LOG_LEVEL'] = 'DEBUG'
    
    run_diagnosis()
