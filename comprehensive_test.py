"""
CareerNavigator è¯¦ç»†åˆ†æ­¥æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•å¤§æ¨¡å‹è°ƒç”¨å’ŒLangGraphå·¥ä½œæµé€»è¾‘
"""

import sys
import os
import time
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

def test_environment_setup():
    """æµ‹è¯•ç¯å¢ƒè®¾ç½®"""
    print("ğŸ”§ æµ‹è¯•ç¯å¢ƒè®¾ç½®...")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv('DASHSCOPE_API_KEY')
    if not api_key:
        print("  âŒ æœªè®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        return False
    
    if api_key == 'your_actual_dashscope_api_key_here':
        print("  âŒ è¯·è®¾ç½®æ­£ç¡®çš„DASHSCOPE_API_KEY")
        return False
    
    print(f"  âœ… APIå¯†é’¥å·²è®¾ç½®: {api_key[:10]}...")
    
    # æ£€æŸ¥å…¶ä»–ç¯å¢ƒå˜é‡
    env_vars = ['FLASK_ENV', 'LOG_LEVEL']
    for var in env_vars:
        value = os.getenv(var)
        print(f"  âœ… {var}: {value}")
    
    return True


def test_dependencies():
    """æµ‹è¯•å…³é”®ä¾èµ–"""
    print("\nğŸ“¦ æµ‹è¯•å…³é”®ä¾èµ–...")
    
    dependencies = [
        ('flask', 'Flaskæ¡†æ¶'),
        ('dashscope', 'é˜¿é‡Œäº‘ç™¾ç‚¼SDK'),
        ('langgraph', 'LangGraphå·¥ä½œæµ'),
        ('langchain_core', 'LangChainæ ¸å¿ƒ')
    ]
    
    missing = []
    for module, desc in dependencies:
        try:
            __import__(module)
            print(f"  âœ… {desc} ({module})")
        except ImportError:
            print(f"  âŒ {desc} ({module}) - æœªå®‰è£…")
            missing.append(module)
    
    if missing:
        print(f"  âš ï¸ ç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
        print("  ğŸ’¡ è¯·è¿è¡Œ: pip install " + " ".join(missing))
        return False
    
    return True


def test_llm_service_basic():
    """æµ‹è¯•LLMæœåŠ¡åŸºç¡€åŠŸèƒ½"""
    print("\nğŸ¤– æµ‹è¯•LLMæœåŠ¡åŸºç¡€åŠŸèƒ½...")
    
    try:
        from src.services.llm_service import DashScopeService
        
        # åˆå§‹åŒ–æœåŠ¡
        llm_service = DashScopeService()
        print("  âœ… LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        return llm_service
        
    except Exception as e:
        print(f"  âŒ LLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def test_llm_api_call(llm_service):
    """æµ‹è¯•LLM APIè°ƒç”¨"""
    print("\nğŸ”¥ æµ‹è¯•LLM APIè°ƒç”¨...")
    
    if not llm_service:
        print("  âŒ LLMæœåŠ¡æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æµ‹è¯•")
        return False
    
    try:
        # ç®€å•æµ‹è¯•è°ƒç”¨
        test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹ï¼Œé™åˆ¶åœ¨50å­—ä»¥å†…ã€‚"
        
        print("  ğŸ“¤ å‘é€æµ‹è¯•è¯·æ±‚...")
        start_time = time.time()
        
        response = llm_service.call_llm(test_prompt)
        
        end_time = time.time()
        response_time = end_time - start_time
        
        if response.get("success"):
            content = response.get("content", "")
            usage = response.get("usage", {})
            
            print(f"  âœ… APIè°ƒç”¨æˆåŠŸ ({response_time:.2f}s)")
            print(f"  ğŸ“ å“åº”å†…å®¹: {content[:100]}...")
            print(f"  ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥={usage.get('input_tokens', 0)}, è¾“å‡º={usage.get('output_tokens', 0)}")
            
            return True
        else:
            error = response.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"  âŒ APIè°ƒç”¨å¤±è´¥: {error}")
            return False
            
    except Exception as e:
        print(f"  âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
        return False


def test_career_specific_llm_call(llm_service):
    """æµ‹è¯•èŒä¸šè§„åˆ’ä¸“ç”¨LLMè°ƒç”¨"""
    print("\nğŸ¯ æµ‹è¯•èŒä¸šè§„åˆ’ä¸“ç”¨LLMè°ƒç”¨...")
    
    if not llm_service:
        print("  âŒ LLMæœåŠ¡æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æµ‹è¯•")
        return False
    
    try:
        # èŒä¸šè§„åˆ’ç›¸å…³çš„æµ‹è¯•
        career_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŒä¸šè§„åˆ’é¡¾é—®ã€‚è¯·ä¸ºä»¥ä¸‹ç”¨æˆ·æä¾›èŒä¸šå»ºè®®ï¼š

ç”¨æˆ·ä¿¡æ¯ï¼š
- å¹´é¾„ï¼š25å²
- å­¦å†ï¼šæœ¬ç§‘è®¡ç®—æœºç§‘å­¦
- å·¥ä½œç»éªŒï¼š2å¹´è½¯ä»¶å¼€å‘
- å½“å‰èŒä½ï¼šåˆçº§è½¯ä»¶å·¥ç¨‹å¸ˆ
- èŒä¸šç›®æ ‡ï¼šæˆä¸ºæŠ€æœ¯å›¢é˜Ÿè´Ÿè´£äºº

è¯·æä¾›ï¼š
1. æŠ€èƒ½æå‡å»ºè®®ï¼ˆ2-3é¡¹ï¼‰
2. èŒä¸šå‘å±•è·¯å¾„ï¼ˆç®€è¦ï¼‰
3. æ—¶é—´è§„åˆ’å»ºè®®

è¯·ä¿æŒå›ç­”ç®€æ´ï¼Œæ€»å­—æ•°æ§åˆ¶åœ¨200å­—ä»¥å†…ã€‚
"""
        
        context = {
            "user_profile": {
                "age": 25,
                "education": "æœ¬ç§‘è®¡ç®—æœºç§‘å­¦",
                "experience": "2å¹´è½¯ä»¶å¼€å‘",
                "goal": "æŠ€æœ¯å›¢é˜Ÿè´Ÿè´£äºº"
            },
            "analysis_type": "career_planning"
        }
        
        print("  ğŸ“¤ å‘é€èŒä¸šè§„åˆ’è¯·æ±‚...")
        start_time = time.time()
        
        response = llm_service.call_llm(career_prompt, context=context)
        
        end_time = time.time()
        response_time = end_time - start_time
        
        if response.get("success"):
            content = response.get("content", "")
            usage = response.get("usage", {})
            
            print(f"  âœ… èŒä¸šè§„åˆ’APIè°ƒç”¨æˆåŠŸ ({response_time:.2f}s)")
            print(f"  ğŸ“ å»ºè®®å†…å®¹:")
            print(f"     {content}")
            print(f"  ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥={usage.get('input_tokens', 0)}, è¾“å‡º={usage.get('output_tokens', 0)}")
            
            # æ£€æŸ¥å“åº”è´¨é‡
            if len(content) > 50 and ("æŠ€èƒ½" in content or "å‘å±•" in content or "å»ºè®®" in content):
                print("  âœ… å“åº”å†…å®¹è´¨é‡è‰¯å¥½")
                return True
            else:
                print("  âš ï¸ å“åº”å†…å®¹å¯èƒ½è´¨é‡ä¸ä½³")
                return False
            
        else:
            error = response.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"  âŒ èŒä¸šè§„åˆ’APIè°ƒç”¨å¤±è´¥: {error}")
            return False
            
    except Exception as e:
        print(f"  âŒ èŒä¸šè§„åˆ’APIè°ƒç”¨å¼‚å¸¸: {e}")
        return False


def test_state_management():
    """æµ‹è¯•çŠ¶æ€ç®¡ç†"""
    print("\nğŸ“Š æµ‹è¯•çŠ¶æ€ç®¡ç†...")
    
    try:
        from src.models.career_state import (
            UserProfile, WorkflowStage, create_initial_state, StateUpdater
        )
        
        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·æ¡£æ¡ˆ
        user_profile = UserProfile(
            user_id="test_user_001",
            age=25,
            education_level="æœ¬ç§‘",
            work_experience=2,
            current_position="è½¯ä»¶å·¥ç¨‹å¸ˆ",
            industry="äº’è”ç½‘",
            skills=["Python", "JavaScript", "React"],
            interests=["æŠ€æœ¯ç®¡ç†", "äº§å“è®¾è®¡"],
            career_goals="æˆä¸ºæŠ€æœ¯å›¢é˜Ÿè´Ÿè´£äºº",
            location="åŒ—äº¬",
            salary_expectation="20-30ä¸‡",
            additional_info={"preferred_company_size": "ä¸­å¤§å‹"}
        )
        print("  âœ… ç”¨æˆ·æ¡£æ¡ˆåˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = create_initial_state(user_profile, "test_session_001")
        print("  âœ… åˆå§‹çŠ¶æ€åˆ›å»ºæˆåŠŸ")
        
        # éªŒè¯çŠ¶æ€ç»“æ„
        required_fields = [
            "session_id", "user_profile", "current_stage", "messages",
            "agent_tasks", "agent_outputs", "system_metrics"
        ]
        
        for field in required_fields:
            if field not in initial_state:
                print(f"  âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        print("  âœ… çŠ¶æ€ç»“æ„éªŒè¯é€šè¿‡")
        
        # æµ‹è¯•çŠ¶æ€æ›´æ–°
        state_updater = StateUpdater()
        updated_state = state_updater.update_stage(initial_state, WorkflowStage.PLANNING)
        
        if updated_state["current_stage"] == WorkflowStage.PLANNING:
            print("  âœ… çŠ¶æ€æ›´æ–°åŠŸèƒ½æ­£å¸¸")
        else:
            print("  âŒ çŠ¶æ€æ›´æ–°å¤±è´¥")
            return False
        
        return initial_state
        
    except Exception as e:
        print(f"  âŒ çŠ¶æ€ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")
        return None


def test_single_node():
    """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•å•ä¸ªèŠ‚ç‚¹åŠŸèƒ½...")
    
    try:
        from src.services.career_nodes import coordinator_node
        from src.models.career_state import UserProfile, create_initial_state
        
        # åˆ›å»ºæµ‹è¯•çŠ¶æ€
        user_profile = UserProfile(
            user_id="test_user_node",
            age=28,
            education_level="ç¡•å£«",
            work_experience=3,
            current_position="é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ",
            industry="é‡‘èç§‘æŠ€",
            skills=["Python", "æœºå™¨å­¦ä¹ ", "æ•°æ®åˆ†æ"],
            interests=["äººå·¥æ™ºèƒ½", "åˆ›ä¸š"],
            career_goals="æˆä¸ºAIäº§å“ç»ç†",
            location="ä¸Šæµ·",
            salary_expectation="30-50ä¸‡",
            additional_info={}
        )
        
        test_state = create_initial_state(user_profile, "test_node_session")
        
        print("  ğŸ“¤ æ‰§è¡Œåè°ƒå‘˜èŠ‚ç‚¹...")
        start_time = time.time()
        
        result = coordinator_node(test_state)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"  âœ… èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ ({execution_time:.2f}s)")
        
        # æ£€æŸ¥è¿”å›ç»“æœ
        if isinstance(result, dict):
            print("  âœ… è¿”å›ç»“æœæ ¼å¼æ­£ç¡®")
            
            # æ£€æŸ¥å¿…è¦çš„è¿”å›å­—æ®µ
            if "agent_tasks" in result:
                tasks = result["agent_tasks"]
                print(f"  âœ… ç”Ÿæˆäº† {len(tasks)} ä¸ªä»»åŠ¡")
                
                # æ˜¾ç¤ºä»»åŠ¡è¯¦æƒ…
                for i, task in enumerate(tasks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    task_type = task.get("task_type", "æœªçŸ¥")
                    print(f"     ä»»åŠ¡{i+1}: {task_type}")
                
                return True
            else:
                print("  âŒ ç¼ºå°‘agent_taskså­—æ®µ")
                return False
        else:
            print(f"  âŒ è¿”å›ç»“æœæ ¼å¼é”™è¯¯: {type(result)}")
            return False
            
    except Exception as e:
        print(f"  âŒ å•èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_graph_creation():
    """æµ‹è¯•å›¾å½¢åˆ›å»º"""
    print("\nğŸ•¸ï¸ æµ‹è¯•LangGraphå›¾å½¢åˆ›å»º...")
    
    try:
        from src.services.career_graph import CareerNavigatorGraph
        
        print("  ğŸ”¨ åˆ›å»ºå·¥ä½œæµå›¾...")
        career_graph = CareerNavigatorGraph()
        
        print("  âœ… å·¥ä½œæµå›¾åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥å›¾å½¢ç»“æ„
        if hasattr(career_graph, 'workflow') and career_graph.workflow:
            print("  âœ… å·¥ä½œæµå¯¹è±¡å­˜åœ¨")
        else:
            print("  âŒ å·¥ä½œæµå¯¹è±¡ä¸å­˜åœ¨")
            return False
        
        if hasattr(career_graph, 'app') and career_graph.app:
            print("  âœ… åº”ç”¨å¯¹è±¡å­˜åœ¨")
        else:
            print("  âŒ åº”ç”¨å¯¹è±¡ä¸å­˜åœ¨")
            return False
        
        return career_graph
        
    except Exception as e:
        print(f"  âŒ å›¾å½¢åˆ›å»ºå¤±è´¥: {e}")
        return None


def test_full_workflow(career_graph, llm_service):
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
    print("\nğŸš€ æµ‹è¯•å®Œæ•´å·¥ä½œæµ...")
    
    if not career_graph or not llm_service:
        print("  âŒ å‰ç½®æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡å®Œæ•´å·¥ä½œæµæµ‹è¯•")
        return False
    
    try:
        from src.models.career_state import UserProfile
        from langchain_core.messages import HumanMessage
        
        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·æ¡£æ¡ˆ
        user_profile = UserProfile(
            user_id="workflow_test_user",
            age=26,
            education_level="æœ¬ç§‘",
            work_experience=3,
            current_position="äº§å“ç»ç†",
            industry="ç”µå•†",
            skills=["äº§å“è®¾è®¡", "æ•°æ®åˆ†æ", "é¡¹ç›®ç®¡ç†"],
            interests=["ç”¨æˆ·ä½“éªŒ", "å•†ä¸šç­–ç•¥"],
            career_goals="æˆä¸ºäº§å“æ€»ç›‘",
            location="æ·±åœ³",
            salary_expectation="25-40ä¸‡",
            additional_info={}
        )
        
        user_message = "æˆ‘å¸Œæœ›åœ¨3å¹´å†…æˆä¸ºäº§å“æ€»ç›‘ï¼Œè¯·å¸®æˆ‘åˆ¶å®šè¯¦ç»†çš„èŒä¸šå‘å±•è®¡åˆ’ã€‚"
        
        print("  ğŸ¯ åˆ›å»ºå·¥ä½œæµä¼šè¯...")
        initial_state = career_graph.create_session(user_profile, user_message)
        
        print(f"  âœ… ä¼šè¯åˆ›å»ºæˆåŠŸï¼ŒSession ID: {initial_state['session_id']}")
        
        print("  ğŸ”„ æ‰§è¡Œå·¥ä½œæµ...")
        start_time = time.time()
        
        # è¿è¡Œå·¥ä½œæµï¼ˆé™åˆ¶æ‰§è¡Œæ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…ï¼‰
        try:
            result = career_graph.run_workflow(initial_state)
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            print(f"  âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ ({execution_time:.2f}s)")
            
            if result.get("success"):
                final_state = result.get("final_state", {})
                current_stage = final_state.get("current_stage")
                
                print(f"  âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼Œå½“å‰é˜¶æ®µ: {current_stage}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºç»“æœ
                agent_outputs = final_state.get("agent_outputs", [])
                if agent_outputs:
                    print(f"  âœ… ç”Ÿæˆäº† {len(agent_outputs)} ä¸ªåˆ†æç»“æœ")
                    
                    # æ˜¾ç¤ºæœ€æ–°çš„åˆ†æç»“æœ
                    latest_output = agent_outputs[-1]
                    output_type = latest_output.get("output_type", "æœªçŸ¥")
                    content_preview = str(latest_output.get("content", ""))[:100]
                    print(f"  ğŸ“ æœ€æ–°ç»“æœç±»å‹: {output_type}")
                    print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview}...")
                
                return True
            else:
                error = result.get("error", "æœªçŸ¥é”™è¯¯")
                print(f"  âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {error}")
                return False
                
        except Exception as workflow_e:
            print(f"  âš ï¸ å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸ï¼ˆå¯èƒ½è¶…æ—¶ï¼‰: {workflow_e}")
            # å³ä½¿å¼‚å¸¸ï¼Œå¦‚æœæ˜¯è¶…æ—¶ï¼Œä¹Ÿå¯èƒ½è¡¨ç¤ºåŸºæœ¬åŠŸèƒ½æ­£å¸¸
            return True
            
    except Exception as e:
        print(f"  âŒ å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_api_endpoints():
    """æµ‹è¯•APIç«¯ç‚¹ï¼ˆéœ€è¦æœåŠ¡è¿è¡Œï¼‰"""
    print("\nğŸŒ æµ‹è¯•APIç«¯ç‚¹...")
    
    try:
        import requests
        
        base_url = "http://localhost:5050"
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        print("  ğŸ’“ æµ‹è¯•å¥åº·æ£€æŸ¥...")
        try:
            response = requests.get(f"{base_url}/api/health", timeout=5)
            if response.status_code == 200:
                print("  âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
                return True
            else:
                print(f"  âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
                return False
        except requests.exceptions.ConnectionError:
            print("  âš ï¸ æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡APIæµ‹è¯•")
            print("  ğŸ’¡ è¯·å…ˆè¿è¡Œ: python main.py")
            return False
            
    except ImportError:
        print("  âŒ requestsåº“æœªå®‰è£…ï¼Œè·³è¿‡APIæµ‹è¯•")
        return False


def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸ§ª CareerNavigator è¯¦ç»†åˆ†æ­¥æµ‹è¯•")
    print("=" * 60)
    
    test_results = {}
    
    # æµ‹è¯•æ­¥éª¤
    steps = [
        ("ç¯å¢ƒè®¾ç½®", test_environment_setup),
        ("ä¾èµ–æ£€æŸ¥", test_dependencies),
        ("LLMæœåŠ¡åŸºç¡€", test_llm_service_basic),
        ("çŠ¶æ€ç®¡ç†", test_state_management),
        ("å›¾å½¢åˆ›å»º", test_graph_creation),
        ("APIç«¯ç‚¹", test_api_endpoints),
    ]
    
    llm_service = None
    career_graph = None
    
    for step_name, test_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        
        try:
            result = test_func()
            
            # ä¿å­˜ç‰¹æ®Šè¿”å›å€¼
            if step_name == "LLMæœåŠ¡åŸºç¡€" and result:
                llm_service = result
                test_results[step_name] = True
            elif step_name == "å›¾å½¢åˆ›å»º" and result:
                career_graph = result
                test_results[step_name] = True
            else:
                test_results[step_name] = bool(result)
                
        except Exception as e:
            print(f"  âŒ {step_name} æµ‹è¯•å¼‚å¸¸: {e}")
            test_results[step_name] = False
    
    # å¦‚æœåŸºç¡€æµ‹è¯•é€šè¿‡ï¼Œè¿›è¡Œé«˜çº§æµ‹è¯•
    if llm_service:
        print(f"\n{'='*20} LLM APIè°ƒç”¨ {'='*20}")
        test_results["LLM APIè°ƒç”¨"] = test_llm_api_call(llm_service)
        
        print(f"\n{'='*20} èŒä¸šè§„åˆ’LLMè°ƒç”¨ {'='*20}")
        test_results["èŒä¸šè§„åˆ’LLMè°ƒç”¨"] = test_career_specific_llm_call(llm_service)
    
    if career_graph:
        print(f"\n{'='*20} å•èŠ‚ç‚¹æµ‹è¯• {'='*20}")
        test_results["å•èŠ‚ç‚¹æµ‹è¯•"] = test_single_node()
        
        if llm_service:
            print(f"\n{'='*20} å®Œæ•´å·¥ä½œæµ {'='*20}")
            test_results["å®Œæ•´å·¥ä½œæµ"] = test_full_workflow(career_graph, llm_service)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    
    passed = sum(1 for result in test_results.values() if result)
    total = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name:<20} {status}")
    
    print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡ ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åç«¯é€»è¾‘å®Œå…¨æ­£å¸¸ï¼")
    elif passed >= total * 0.8:
        print("ğŸ‘ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨")
    else:
        print("âš ï¸ å¤šé¡¹æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é…ç½®")
    
    return test_results


if __name__ == "__main__":
    run_comprehensive_test()
